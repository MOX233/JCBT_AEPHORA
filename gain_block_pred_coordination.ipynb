{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383fa118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Configure which GPU\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from utils.NN_utils import BeamPredictionModel, BlockPredictionModel, BestGainPredictionModel\n",
    "from utils.NN_utils import BeamPredictionLSTMModel, BlockPredictionLSTMModel, BestGainPredictionLSTMModel\n",
    "from utils.NN_utils import preprocess_data\n",
    "from utils.options import args_parser\n",
    "from utils.mox_utils import setup_seed, get_save_dirs, np2torch, save_NN_results\n",
    "from utils.data_utils import get_prepared_dataset, prepare_dataset\n",
    "from utils.beam_utils import generate_dft_codebook, beamIdPair_to_beamPairId, beamPairId_to_beamIdPair\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seed(20)\n",
    "freq = 28e9\n",
    "DS_start, DS_end = 800, 900\n",
    "preprocess_mode = 2\n",
    "pos_in_data = preprocess_mode==2\n",
    "look_ahead_len = 1\n",
    "n_pilot = 16\n",
    "M_r, N_bs, M_t = 8, 4, 64\n",
    "P_t = 1e-1\n",
    "P_noise = 1e-14 # -174dBm/Hz * 1.8MHz = 7.165929069962946e-15 W\n",
    "gpu = 4\n",
    "device = f'cuda:{gpu}' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device: ', device)\n",
    "\n",
    "prepared_dataset_filename, data_np, veh_h_np, veh_pos_np, best_beam_pair_index_np \\\n",
    "    = get_prepared_dataset(preprocess_mode, DS_start, DS_end, M_t, M_r, freq, n_pilot, N_bs, P_t, P_noise, look_ahead_len)\n",
    "data_torch = np2torch(data_np[:,0,...],device) \n",
    "veh_h_torch = np2torch(veh_h_np[:,-1,...],device) \n",
    "veh_pos_torch = np2torch(veh_pos_np[:,-1,...],device) \n",
    "best_beam_pair_index_torch = np2torch(best_beam_pair_index_np[:,-1,...],device)\n",
    "block_labels = (veh_h_torch[:,0,:,0]==0).long().to(device)\n",
    "DFT_tx = generate_dft_codebook(M_t)\n",
    "DFT_rx = generate_dft_codebook(M_r)\n",
    "beamPairId = best_beam_pair_index_torch.detach().cpu().numpy()\n",
    "beamIdPair = beamPairId_to_beamIdPair(beamPairId,M_t,M_r)\n",
    "num_car, _, num_bs, _ = veh_h_torch.shape\n",
    "channel = veh_h_torch.detach().cpu().numpy()\n",
    "g_opt = np.zeros((num_car,num_bs)).astype(np.float32)\n",
    "for veh in range(num_car):\n",
    "    for bs in range(num_bs):\n",
    "        g_opt[veh,bs] = 1/np.sqrt(M_t*M_r)*np.abs(np.matmul(np.matmul(channel[veh,:,bs,:], DFT_tx[:,beamIdPair[veh,bs,0]]).T.conjugate(),DFT_rx[:,beamIdPair[veh,bs,1]]))\n",
    "        g_opt[veh,bs] = 20 * np.log10(g_opt[veh,bs] + 1e-9) \n",
    "g_opt_normalized = g_opt / 20 + 7\n",
    "gain_labels = torch.tensor(g_opt_normalized).to(device)\n",
    "\n",
    "feature_input_dim = data_torch.shape[-1] * 2 - pos_in_data * 2\n",
    "num_bs = 4\n",
    "num_beampair = M_t * M_r\n",
    "\n",
    "beam_pred_model = BeamPredictionModel(feature_input_dim, num_bs, num_beampair).to(device)\n",
    "block_pred_model = BlockPredictionModel(feature_input_dim, num_bs).to(device)\n",
    "gain_pred_model = BestGainPredictionModel(feature_input_dim, num_bs).to(device)\n",
    "\n",
    "beam_pred_model.load_state_dict(torch.load('NN_result/400_800_3Dbeam_tx(1,64)_rx(1,8)_freq2.8e+10_Np16_mode2_lookahead1/models/beampred_valAcc87.67%_2025-04-22_17:45:51.pth'))\n",
    "block_pred_model.load_state_dict(torch.load('NN_result/400_800_3Dbeam_tx(1,64)_rx(1,8)_freq2.8e+10_Np16_mode2_lookahead1/models/blockpred_valAcc98.03%_2025-04-22_17:59:06.pth'))\n",
    "gain_pred_model.load_state_dict(torch.load('NN_result/400_800_3Dbeam_tx(1,64)_rx(1,8)_freq2.8e+10_Np16_mode2_lookahead1/models/gainpred_valMae2.50dB_2025-04-22_18:02:25.pth'))\n",
    "\n",
    "data = preprocess_data(data_torch, pos_in_data)\n",
    "beam_pred_model.eval()\n",
    "block_pred_model.eval()\n",
    "gain_pred_model.eval()\n",
    "with torch.no_grad():\n",
    "    beam_pred = beam_pred_model(data).argmax(dim=-1)\n",
    "    block_pred = block_pred_model(data).argmax(dim=-1)\n",
    "    gain_pred = gain_pred_model.pred(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32492943",
   "metadata": {},
   "outputs": [],
   "source": [
    "(block_pred == block_labels).to(torch.float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd2f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs((gain_pred.detach().cpu().numpy() - g_opt)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ebd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_pred.max(), gain_pred.min(), g_opt.max(), g_opt.min() #  -69.123604~-148.2894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535187f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gain_pred and block_pred coordination\n",
    "np.abs(((gain_pred*(1-block_pred) - 180.*block_pred).detach().cpu().numpy() - g_opt)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a9cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip gain_pred\n",
    "gain_pred_clipLB = gain_pred*(gain_pred>=-180.) - 180.*(gain_pred<-180.)\n",
    "np.abs((gain_pred_clipLB.detach().cpu().numpy() - g_opt)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7c62b",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seed(20)\n",
    "freq = 28e9\n",
    "DS_start, DS_end = 800, 900\n",
    "preprocess_mode = 2\n",
    "pos_in_data = preprocess_mode==2\n",
    "look_ahead_len = 3\n",
    "n_pilot = 16\n",
    "M_r, N_bs, M_t = 8, 4, 64\n",
    "P_t = 1e-1\n",
    "P_noise = 1e-14 # -174dBm/Hz * 1.8MHz = 7.165929069962946e-15 W\n",
    "gpu = 4\n",
    "device = f'cuda:{gpu}' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device: ', device)\n",
    "\n",
    "prepared_dataset_filename, data_np, veh_h_np, veh_pos_np, best_beam_pair_index_np \\\n",
    "    = get_prepared_dataset(preprocess_mode, DS_start, DS_end, M_t, M_r, freq, n_pilot, N_bs, P_t, P_noise, look_ahead_len)\n",
    "data_torch = np2torch(data_np[:,:-1,...],device) \n",
    "veh_h_torch = np2torch(veh_h_np[:,-1,...],device) \n",
    "veh_pos_torch = np2torch(veh_pos_np[:,-1,...],device) \n",
    "best_beam_pair_index_torch = np2torch(best_beam_pair_index_np[:,-1,...],device)\n",
    "block_labels = (veh_h_torch[:,0,:,0]==0).long().to(device)\n",
    "DFT_tx = generate_dft_codebook(M_t)\n",
    "DFT_rx = generate_dft_codebook(M_r)\n",
    "beamPairId = best_beam_pair_index_torch.detach().cpu().numpy()\n",
    "beamIdPair = beamPairId_to_beamIdPair(beamPairId,M_t,M_r)\n",
    "num_car, _, num_bs, _ = veh_h_torch.shape\n",
    "channel = veh_h_torch.detach().cpu().numpy()\n",
    "g_opt = np.zeros((num_car,num_bs)).astype(np.float32)\n",
    "for veh in range(num_car):\n",
    "    for bs in range(num_bs):\n",
    "        g_opt[veh,bs] = 1/np.sqrt(M_t*M_r)*np.abs(np.matmul(np.matmul(channel[veh,:,bs,:], DFT_tx[:,beamIdPair[veh,bs,0]]).T.conjugate(),DFT_rx[:,beamIdPair[veh,bs,1]]))\n",
    "        g_opt[veh,bs] = 20 * np.log10(g_opt[veh,bs] + 1e-9) \n",
    "g_opt_normalized = g_opt / 20 + 7\n",
    "gain_labels = torch.tensor(g_opt_normalized).to(device)\n",
    "\n",
    "feature_input_dim = data_torch.shape[-1] * 2 - pos_in_data * 2\n",
    "num_bs = 4\n",
    "num_beampair = M_t * M_r\n",
    "\n",
    "beam_pred_lstm_model = BeamPredictionLSTMModel(feature_input_dim, num_bs, num_beampair).to(device)\n",
    "block_pred_lstm_model = BlockPredictionLSTMModel(feature_input_dim, num_bs).to(device)\n",
    "gain_pred_lstm_model = BestGainPredictionLSTMModel(feature_input_dim, num_bs).to(device)\n",
    "\n",
    "beam_pred_lstm_model.load_state_dict(torch.load('NN_result/400_800_3Dbeam_tx(1,64)_rx(1,8)_freq2.8e+10_Np16_mode2_lookahead3/models/beampred_lstm_valAcc87.48%_2025-04-22_16:58:35.pth'))\n",
    "block_pred_lstm_model.load_state_dict(torch.load('NN_result/400_800_3Dbeam_tx(1,64)_rx(1,8)_freq2.8e+10_Np16_mode2_lookahead3/models/blockpred_lstm_valAcc98.35%_2025-04-22_16:58:42.pth'))\n",
    "gain_pred_lstm_model.load_state_dict(torch.load('NN_result/400_800_3Dbeam_tx(1,64)_rx(1,8)_freq2.8e+10_Np16_mode2_lookahead3/models/gainpred_lstm_valMae2.51dB_2025-04-22_17:03:25.pth'))\n",
    "\n",
    "data = preprocess_data(data_torch, pos_in_data)\n",
    "beam_pred_model.eval()\n",
    "block_pred_model.eval()\n",
    "gain_pred_model.eval()\n",
    "with torch.no_grad():\n",
    "    beam_pred = beam_pred_lstm_model(data).argmax(dim=-1)\n",
    "    block_pred = block_pred_lstm_model(data).argmax(dim=-1)\n",
    "    gain_pred = gain_pred_lstm_model.pred(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0556d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "(block_pred == block_labels).to(torch.float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c11477",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs((gain_pred.detach().cpu().numpy() - g_opt)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e638b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_pred.max(), gain_pred.min(), g_opt.max(), g_opt.min() #  -69.123604~-148.2894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gain_pred and block_pred coordination\n",
    "np.abs(((gain_pred*(1-block_pred) - 180.*block_pred).detach().cpu().numpy() - g_opt)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c769b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip gain_pred\n",
    "gain_pred_clipLB = gain_pred*(gain_pred>=-180.) - 180.*(gain_pred<-180.)\n",
    "np.abs((gain_pred_clipLB.detach().cpu().numpy() - g_opt)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909c2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "(gain_pred.detach().cpu().numpy()-g_opt).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139fe587",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist((gain_pred.detach().cpu().numpy()-g_opt).reshape(-1), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_pred.shape, gain_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_pred_lstm_model(data).shape, gain_pred_lstm_model.pred(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eb966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_block_pred_lstm_model = block_pred_lstm_model(data)\n",
    "output_gain_pred_lstm_model = gain_pred_lstm_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_block_pred_lstm_model.shape, output_block_pred_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e15e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_gain_pred_lstm_model.shape, output_gain_pred_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e2102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.softmax(output_block_pred_lstm_model, dim=-1).argmax(dim=-1).shape, torch.nn.functional.softmax(output_block_pred_lstm_model, dim=-1).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e905611",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_loc = ~(block_labels == torch.nn.functional.softmax(output_block_pred_lstm_model, dim=-1).argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5641efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac3eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c8fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09797054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda:7\n"
     ]
    }
   ],
   "source": [
    "import os # Configure which GPU\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# from utils.NN_utils import BeamPredictionModel, train_beampred_lstm_model\n",
    "from utils.NN_utils import BeamPredictionModel, train_beampred_lstm_model\n",
    "from utils.options import args_parser\n",
    "from utils.mox_utils import setup_seed, get_save_dirs, save_NN_results\n",
    "from utils.plot_utils import plot_record_metrics\n",
    "from utils.data_utils import get_prepared_dataset, prepare_dataset\n",
    "\n",
    "\n",
    "# 设置随机数种子\n",
    "setup_seed(20)\n",
    "freq = 28e9\n",
    "DS_start, DS_end = 400, 800\n",
    "preprocess_mode = 2\n",
    "look_ahead_len = 3\n",
    "n_pilot = 16\n",
    "M_r, N_bs, M_t = 8, 4, 64\n",
    "P_t = 1e-1\n",
    "P_noise = 1e-14 # -174dBm/Hz * 1.8MHz = 7.165929069962946e-15 W\n",
    "gpu = 7\n",
    "device = f'cuda:{gpu}' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device: ', device)\n",
    "\n",
    "prepared_dataset_filename, data_np, veh_h_np, veh_pos_np, best_beam_pair_index_np \\\n",
    "    = get_prepared_dataset(preprocess_mode, DS_start, DS_end, M_t, M_r, freq, n_pilot, N_bs, P_t, P_noise, look_ahead_len)\n",
    "data_torch = torch.tensor(data_np[:,:-1,...]) \n",
    "veh_h_torch = torch.tensor(veh_h_np[:,-1,...]) \n",
    "veh_pos_torch = torch.tensor(veh_pos_np[:,-1,...]) \n",
    "best_beam_pair_index_torch = torch.tensor(best_beam_pair_index_np[:,-1,...])\n",
    "\n",
    "# 数据增强 将原长度为look_ahead_len的序列进行截断处理\n",
    "lengths = [look_ahead_len]*len(data_np)\n",
    "for input_seq_len in range(look_ahead_len-1, 0, -1):\n",
    "    # input_seq_len 2,1\n",
    "    data_np_clipped = np.zeros_like(data_np[:,:-1,...])\n",
    "    data_np_clipped[:,:input_seq_len,...] = data_np[:,-input_seq_len-1:-1,...]\n",
    "    data_torch = torch.concat((data_torch, torch.tensor(data_np_clipped)), dim=0)\n",
    "    lengths.extend([input_seq_len]*len(data_np_clipped))\n",
    "    veh_h_torch = torch.concat((veh_h_torch, torch.tensor(veh_h_np[:,-1,...])), dim=0)\n",
    "    veh_pos_torch = torch.concat((veh_pos_torch, torch.tensor(veh_pos_np[:,-1,...])), dim=0)\n",
    "    best_beam_pair_index_torch = torch.concat((best_beam_pair_index_torch, torch.tensor(best_beam_pair_index_np[:,-1,...])), dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bda4abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_torch_cut = data_torch[::10000,...]\n",
    "lengths_cut = np.array(lengths)[::10000,...]\n",
    "pack_padded_data_torch = torch.nn.utils.rnn.pack_padded_sequence(data_torch_cut, lengths_cut, batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a001c2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/sionna/lib/python3.10/site-packages/torch/nn/utils/rnn.py:155: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at /pytorch/aten/src/ATen/native/Copy.cpp:308.)\n",
      "  data = self.data.to(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from utils.NN_utils import BeamPredictionLSTMModel\n",
    "\n",
    "lstm_model = torch.nn.LSTM(\n",
    "            input_size=130,\n",
    "            hidden_size=32,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        ).to(device)\n",
    "\n",
    "\n",
    "packed_out, hidden =  lstm_model(pack_padded_data_torch.to(torch.float).to(device))\n",
    "(PackedSequence, batch_sizes, sorted_indices, unsorted_indices) = packed_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66874328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 105, 32]), torch.Size([1, 105, 32]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0].shape, hidden[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63debd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([210, 32]), tensor([105,  70,  35]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PackedSequence.shape, batch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5816de",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_unpacked, valid_lengths = torch.nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af70704f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([105, 3, 32]),\n",
       " tensor([[[ 9.4247e-02,  7.4599e-11, -1.7691e-22,  ..., -1.6173e-04,\n",
       "            1.7199e-02, -1.4099e-02],\n",
       "          [ 9.9912e-02,  9.3010e-11, -1.5589e-22,  ..., -1.2791e-04,\n",
       "            1.6201e-02, -1.3515e-02],\n",
       "          [ 8.7493e-02,  1.1500e-10, -1.4372e-22,  ..., -1.2990e-04,\n",
       "            2.0431e-02, -1.6299e-02]],\n",
       " \n",
       "         [[-2.5680e-09, -2.9711e-26, -7.6159e-01,  ...,  3.5282e-04,\n",
       "           -9.4532e-34,  9.3365e-34],\n",
       "          [-4.6121e-09, -2.5454e-26, -7.6159e-01,  ...,  5.4317e-04,\n",
       "           -1.0317e-33,  1.2130e-33],\n",
       "          [-6.0852e-09, -3.9183e-26, -7.6159e-01,  ...,  6.4369e-04,\n",
       "           -1.9368e-33,  2.4568e-33]],\n",
       " \n",
       "         [[-5.0990e-16,  9.4696e-17,  2.7420e-12,  ...,  5.9959e-17,\n",
       "           -1.1768e-05, -4.5151e-15],\n",
       "          [-7.7781e-16,  1.2268e-16,  4.9919e-12,  ...,  6.0626e-17,\n",
       "           -2.2044e-05, -1.0320e-14],\n",
       "          [-1.2402e-15,  1.5581e-16,  7.1382e-12,  ...,  7.0224e-17,\n",
       "           -3.2520e-05, -1.7561e-14]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.5382e-07,  1.5769e-08, -9.5643e-30,  ..., -8.2553e-05,\n",
       "            7.6159e-01, -7.6147e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[ 1.6612e-27,  7.6159e-01,  8.7780e-25,  ..., -7.5659e-01,\n",
       "            7.5838e-01, -7.6159e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[ 7.0309e-22,  4.8366e-02,  8.9078e-17,  ..., -2.1224e-05,\n",
       "           -2.5666e-01, -5.9518e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]], device='cuda:7',\n",
       "        grad_fn=<IndexSelectBackward0>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_unpacked.shape, out_unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0adfa872",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd = out_unpacked[torch.arange(out_unpacked.shape[0]), valid_lengths-1, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81f8f09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000e+00,  7.6159e-01,  1.2331e-43,  7.6159e-01,  0.0000e+00,\n",
       "          -0.0000e+00,  2.0207e-26, -0.0000e+00, -2.1578e-15,  1.6910e-23,\n",
       "          -7.6159e-01,  1.3482e-09,  0.0000e+00,  1.1225e-36,  0.0000e+00,\n",
       "           3.1947e-17,  1.9552e-17,  3.0804e-21,  7.6159e-01,  2.8026e-45,\n",
       "           1.3438e-24,  1.1405e-13,  7.5342e-01, -1.0125e-01, -7.6159e-01,\n",
       "          -1.5728e-19, -0.0000e+00, -6.5850e-01, -3.8912e-16, -7.5832e-01,\n",
       "           7.6159e-01, -7.6159e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]], device='cuda:7',\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor([ 0.0000e+00,  7.6159e-01,  1.2331e-43,  7.6159e-01,  0.0000e+00,\n",
       "         -0.0000e+00,  2.0207e-26, -0.0000e+00, -2.1578e-15,  1.6910e-23,\n",
       "         -7.6159e-01,  1.3482e-09,  0.0000e+00,  1.1225e-36,  0.0000e+00,\n",
       "          3.1947e-17,  1.9552e-17,  3.0804e-21,  7.6159e-01,  2.8026e-45,\n",
       "          1.3438e-24,  1.1405e-13,  7.5342e-01, -1.0125e-01, -7.6159e-01,\n",
       "         -1.5728e-19, -0.0000e+00, -6.5850e-01, -3.8912e-16, -7.5832e-01,\n",
       "          7.6159e-01, -7.6159e-01], device='cuda:7', grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_unpacked[100], ddd[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303a3af",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'dims'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mddd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'dims'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9466fddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]) is not False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8458e799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sionna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
